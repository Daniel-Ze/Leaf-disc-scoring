{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This is part of the publication on automated detection of downy mildew on leaf discs.\n",
    "\n",
    "**High-throughput phenotyping of leaf discs infected with grapevine downy mildew using trained convolutional neural networks**\\\n",
    "Zendler D, Nagarjun M, Schwandner A, Hausmann L, Zyprian E\n",
    "\n",
    "Please be aware that further reading is required to get reasonable results. The code presented here was used to generated the CNN models for the above mentioned publication.\n",
    "\n",
    "## 1. Load all the things:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pathlib import Path\n",
    "from pathlib import PurePath\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Conv2D, MaxPooling2D\n",
    "from keras.layers import Activation, Dropout, Flatten, Dense\n",
    "from keras.optimizers import RMSprop\n",
    "from keras.optimizers import Adam\n",
    "from keras.optimizers import Nadam\n",
    "from keras.optimizers import Adadelta\n",
    "from keras.optimizers import SGD\n",
    "from keras.preprocessing.image import ImageDataGenerator, array_to_img, img_to_array, load_img"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Define all the variables needed\n",
    "\n",
    "First off we will define a few parameters that will help us for the downstream code:\n",
    "  - dropout = this will be adjusted in case out CNN is overfitting\n",
    "  - learning_rate = this will influence big the weights adjustments will be\n",
    "  - batch_size = the number of images that is analyzed in a batch\n",
    "  - train_dir = path to the training data\n",
    "  - val_dir = path to the validation data\n",
    "  - img_size = the pixel resolution of the image slices\n",
    "  - nr_train_img = the total number of training images (calss1 + class2)\n",
    "  - nr_val_img = the total number of validation images (class1 + class2)\n",
    "  - nr_epoch = the number of epochs for training the CNN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Change this to something between 0.2 and 0.5\n",
    "dropout = 0.5\n",
    "\n",
    "# For RMSprop, Adam, Nadam the learning rate should be around 0.001 - 0.0001\n",
    "# For Adadelta the learning rate has to be set to 0.1\n",
    "# For SGD the learning rate should be set to 0.01\n",
    "learning_rate = 0.0001\n",
    "\n",
    "# Increase or dcrease this number according to your system\n",
    "batch_size = 16\n",
    "\n",
    "# The directory in which we stored the training and validation data for the two different classes.\n",
    "# !!! Make sure to adjust this !!!\n",
    "train_dir = 'data4_update/train/'\n",
    "val_dir = 'data4_update/validation/'\n",
    "\n",
    "# Image resolution in pixels for the image slices\n",
    "x = 100 #height\n",
    "y = 119 #width\n",
    "img_size = (x, y, 3)\n",
    "\n",
    "# Number of training and validation images\n",
    "nr_train_img = 1936 # don't forget\n",
    "nr_val_img = 874  # don't forget\n",
    "\n",
    "# Number of training epochs; for testing 5 for final training 15 - 30\n",
    "nr_epoch = 30"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Set up the CNN\n",
    "\n",
    "Let's generate the CNN:\n",
    "  - we chose 3 four convolution layers with 32, 32, 64 and 128 nodes\n",
    "  - each layer has the ReLU activation function\n",
    "  - each layer is pooled by 2 x 2 (see MaxPooling2D for more information)\n",
    "  - Two dense layers with each 256 inputs\n",
    "\n",
    "Please be aware that you might have to change the architecture of your network according to your data. Also the used optimizer is a thing of trail and error."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = Sequential()\n",
    "model.add(Conv2D(32, (3, 3), input_shape=(img_size), kernel_initializer='he_normal'))\n",
    "model.add(Activation('relu'))\n",
    "model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "\n",
    "model.add(Conv2D(32, (3, 3), kernel_initializer='he_normal'))\n",
    "model.add(Activation('relu'))\n",
    "model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "\n",
    "model.add(Conv2D(64, (3, 3), kernel_initializer='he_normal'))\n",
    "model.add(Activation('relu'))\n",
    "model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "\n",
    "model.add(Conv2D(128, (3, 3), kernel_initializer='he_normal'))\n",
    "model.add(Activation('relu'))\n",
    "model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "\n",
    "model.add(Flatten())  # this converts our 3D feature maps to 1D feature vectors\n",
    "model.add(Dense(512))\n",
    "model.add(Activation('relu'))\n",
    "model.add(Dropout(dropout))\n",
    "model.add(Dense(512))\n",
    "model.add(Activation('relu'))\n",
    "model.add(Dropout(dropout))\n",
    "model.add(Dense(1024))\n",
    "model.add(Activation('relu'))\n",
    "model.add(Dropout(dropout))\n",
    "model.add(Dense(1))\n",
    "model.add(Activation('sigmoid'))\n",
    "\n",
    "model.compile(loss='binary_crossentropy',\n",
    "              optimizer=Nadam(lr=learning_rate),\n",
    "              metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Create image data generators and image data augmentation\n",
    "\n",
    "Next we will generate a ImageDataGenerator. This is a helpful tool when the number of images is limited.\n",
    "The ImageDataGenerator will perform socalled image augmentation with out images. This means the images will changed slightly according to the supplied options. This will hopefully give the model more flexibility e.g. in terms of differing light conditions.\\\n",
    "This will be done only for the training images as we want to validate the model with not augmented data.\n",
    "\n",
    "\n",
    "Further with the option rescale we change the values of the RGB picture from training and validation that ranges from 1 to 255 to values between 0 and 1. This is needed for tensorflow.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_datagen = ImageDataGenerator(\n",
    "        rescale=1./255,              # Rescaling the RGB values to a number between 0 and 1\n",
    "        shear_range=0.2,             # Shear angle in counter-clockwise direction in degrees\n",
    "        zoom_range=0.2,              # Range for random zoom\n",
    "        horizontal_flip=True,        # Random horizontal flipping of the image\n",
    "        vertical_flip=True)          # Random vertical flipping of the image\n",
    "#        brightness_range=[0.5,1.5])  # Randomly adjusting the brightness\n",
    "#        width_shift_range=0.2,\n",
    "#        height_shift_range=0.2)\n",
    "\n",
    "test_datagen = ImageDataGenerator(rescale=1./255)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4.1 Have a look at the image data augmentation\n",
    "\n",
    "Next we will visualize the image augmentation options from above to get an impression what is going to be done with the images and if that makes sense.\n",
    "\n",
    "\n",
    "Please specify an image from one of the classes in the training directory. Idealy you want to see something like this:\n",
    "\n",
    "\n",
    "![img_augmentation](img_augmen.png)\n",
    "\n",
    "\n",
    "(If there are more than 9 images in the training folder after testing the augmentation this will throw an error.)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "img_path = 'data4_update/train/spo/LDA_Plate1_I_s06.jpg_10_17.png' # Specify a image from your training data to visualize the image augmentation preview\n",
    "\n",
    "try:\n",
    "    img = load_img(img_path)\n",
    "except:\n",
    "    print(\"No file path supplied\")\n",
    "else:\n",
    "    img = load_img(img_path)\n",
    "    img_array = img_to_array(img)\n",
    "    img_array_reshape = img_array.reshape((1,) + img_array.shape)  \n",
    "    i = 0\n",
    "    for batch in train_datagen.flow(img_array_reshape, batch_size=1,\n",
    "                                    save_to_dir=train_dir, \n",
    "                                    save_prefix='augmentation_preview', \n",
    "                                    save_format='jpeg'):\n",
    "        i += 1\n",
    "        if i > 8:\n",
    "            break  # otherwise the generator would loop indefinitely\n",
    "\n",
    "    data_dir = Path(train_dir)\n",
    "    image_list = list(data_dir.glob('*.jpeg'))\n",
    "    n_images = len(image_list)\n",
    "    \n",
    "    if n_images == 9:\n",
    "        plt.figure(figsize=(10, 10))\n",
    "        for i in range(n_images):\n",
    "            img = load_img(image_list[i]) \n",
    "            ax = plt.subplot(3, 3, i + 1)\n",
    "            plt.imshow(img)\n",
    "            plt.axis(\"off\")\n",
    "        plt.show()\n",
    "        print(\"Check \"+train_dir+(\" for results (and remove them if you don't need them anymore).\"))\n",
    "    else:\n",
    "        print(\"Error: Too many images in folder. Please delete old ones first.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. Load the image data for training and validation\n",
    "\n",
    "Next step is to load our image data with the ImageDataGenerators that we defined before:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_generator = train_datagen.flow_from_directory(\n",
    "        train_dir,  \n",
    "        target_size=(x, y),\n",
    "        batch_size=batch_size,\n",
    "        class_mode='binary')\n",
    "\n",
    "validation_generator = test_datagen.flow_from_directory(\n",
    "        val_dir,\n",
    "        target_size=(x, y),\n",
    "        batch_size=batch_size,\n",
    "        class_mode='binary')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6. Train the CNN model\n",
    "\n",
    "Now that we have everything set up we can start the model training of our defined CNN. The variables batch size, number of epochs, number of training and validation images have been defined at the very beginning. Have a quick look if everythings fine before you start the training. Training and validation progress is saved in 'history'."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "history = model.fit(\n",
    "        train_generator,\n",
    "        steps_per_epoch=nr_train_img // batch_size,\n",
    "        epochs=nr_epoch,\n",
    "        validation_data=validation_generator,\n",
    "        validation_steps=nr_val_img // batch_size)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 7. Visualize what your computer just did for you\n",
    "\n",
    "We plot now the training and validation data for accuracy and loss during the model training. The output from above is further formatted using pandas so that you can go ahead and use it in your favorite program for plotting data.\n",
    "\n",
    "\n",
    "Ideally you would want to see something like this:\n",
    "\n",
    "![train_val](train_val.png)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import numpy\n",
    "\n",
    "acc = history.history['accuracy']\n",
    "val_acc = history.history['val_accuracy']\n",
    "\n",
    "loss = history.history['loss']\n",
    "val_loss = history.history['val_loss']\n",
    "\n",
    "epochs_range = range(nr_epoch)\n",
    "\n",
    "plt.figure(figsize=(15, 6))\n",
    "plt.subplot(1, 2, 1)\n",
    "plt.plot(epochs_range, acc, label='Training Accuracy')\n",
    "plt.plot(epochs_range, val_acc, label='Validation Accuracy')\n",
    "plt.legend(loc='lower right')\n",
    "plt.title('Training and Validation Accuracy')\n",
    "\n",
    "plt.subplot(1, 2, 2)\n",
    "plt.plot(epochs_range, loss, label='Training Loss')\n",
    "plt.plot(epochs_range, val_loss, label='Validation Loss')\n",
    "plt.legend(loc='upper right')\n",
    "plt.title('Training and Validation Loss')\n",
    "plt.show()\n",
    "\n",
    "import pandas as pd\n",
    "\n",
    "df = pd.DataFrame(history.history)\n",
    "\n",
    "print(df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 8. Evaluating your model\n",
    "\n",
    "Now that you have trained a model it's time to evaluate it. We use the eval data that you have prepared next to the training and validation data. For that we load the data from the directory the same way we loaded the validation data.\n",
    "\n",
    "\n",
    "Make sure to pass a directory to eval_dir."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 4960 images belonging to 2 classes.\n"
     ]
    }
   ],
   "source": [
    "eval_dir = 'eval_nagarjun/'\n",
    "evaluate_datagen = ImageDataGenerator(rescale=1./255)\n",
    "evaluation_generator = evaluate_datagen.flow_from_directory(\n",
    "        eval_dir,\n",
    "        target_size=(x, y),\n",
    "        batch_size=batch_size,\n",
    "        class_mode='binary')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "And we run the evaluate() method."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "310/310 [==============================] - 13s 41ms/step - loss: 0.2062 - accuracy: 0.9506\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'loss': 0.2062116414308548, 'accuracy': 0.9506048560142517}"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.evaluate(evaluation_generator, return_dict = True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Success! You went through all steps for training a model. The steps up to here have to be repeated several times until you figure out your model with the best fit for your data. Don't be discouraged if it takes a while!\n",
    "\n",
    "\n",
    "If you have a good fit you can continue to save the model and its weights."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 9. Save your data\n",
    "\n",
    "Now you have seen the training/validation accuracy and loss graph and tested your new model with the evaluation data. If the values are nice and shiny it's time to save them. Adjust your naming accordingly. I tried to fit all important parameters into the naming for you to recognize it later again."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dir_path = Path(train_dir)\n",
    "data_dir_path = train_dir_path.parent\n",
    "data_dir_name = data_dir_path.name\n",
    "\n",
    "weights_file = PurePath(data_dir_path, data_dir_name + \"_model\" + str(dropout) + \"_lr\" + str(learning_rate) + \"_ep\" + str(nr_epoch) + \"_weights.h5\")\n",
    "print(weights_file)\n",
    "model_file = PurePath(data_dir_path, data_dir_name + \"_model\" + str(dropout) + \"_lr\" + str(learning_rate) + \"_ep\" + str(nr_epoch) + \".h5\")\n",
    "print(model_file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.save_weights(weights_file)\n",
    "model.save(model_file)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
